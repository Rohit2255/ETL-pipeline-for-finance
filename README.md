📊 ETL Pipeline for Financial Data  #100DaysOfDataScience

This project focuses on building a complete ETL (Extract, Transform, Load) pipeline for processing financial stock market data. It automates the process of fetching raw stock data, generating technical indicators, and preparing the dataset for machine learning models and dashboards.

🚀 Project Overview
Objective:
To design and implement a modular ETL pipeline that transforms raw historical stock price data into a clean, feature-rich dataset suitable for ML modeling and real-time dashboarding.

Pipeline Stages:

Extract: Load stock data from CSV (or API in future versions)

Transform: Add technical indicators, create target variables, clean and align data

Load: Save the transformed dataset to CSV or DB for downstream tasks



🧠 Use Case
Building this pipeline helps in preparing consistent and repeatable data for:

Stock price movement prediction

Trading strategy simulation

Financial dashboarding

Model training pipelines



🛠️ Tech Stack
Tool	Usage
Python	Core programming
Pandas	Data wrangling and transformation
TA	Technical analysis indicators
Matplotlib	Data visualization
XGBoost	Optional: downstream classification model
scikit-learn	Preprocessing and evaluation

🧱 Features Engineered
📉 RSI (Relative Strength Index)

📈 MACD (Moving Average Convergence Divergence)

📊 EMA (Exponential Moving Average)

📍 Momentum

📏 Bollinger Bands

⏳ Stochastic Oscillator

🎯 Target Variable: 1 if next day's price is higher, else 0



## 📬 Connect With Me

- [LinkedIn](https://www.linkedin.com/in/rohit-yadav)
- [GitHub](https://github.com/yourusername)
- [Portfolio](https://yourportfolio.com)
